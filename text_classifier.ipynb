{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c1W6_ay0nIfx",
    "outputId": "4df64513-5d9d-4791-d01d-9b6928a3ed8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bc6_r96MOamk",
    "outputId": "2741c14b-8bdd-4be5-dfe3-75ec7fad811d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLJbA85ipUF5",
    "outputId": "4b6214f7-63c2-4ed2-f41c-15d203bb20b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_distribution = data['v1'].value_counts()\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtgmBrB1pYnF",
    "outputId": "6276c100-4cd1-4ee7-94d5-ceab52238f75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Unnamed: 2    50\n",
       " Unnamed: 3    12\n",
       " Unnamed: 4     6\n",
       " dtype: int64,\n",
       "                                             Unnamed: 2             Unnamed: 3  \\\n",
       " 95                                         PO Box 5249   MK17 92H. 450Ppw 16\"   \n",
       " 281   the person is definitely special for u..... B...       why to miss them   \n",
       " 444   HOWU DOIN? FOUNDURSELF A JOBYET SAUSAGE?LOVE ...                    NaN   \n",
       " 671   wanted to say hi. HI!!!\\\" Stop? Send STOP to ...                    NaN   \n",
       " 710    this wont even start........ Datz confidence..\"                    NaN   \n",
       " \n",
       "                          Unnamed: 4  \n",
       " 95                              NaN  \n",
       " 281   just Keep-in-touch\\\" gdeve..\"  \n",
       " 444                             NaN  \n",
       " 671                             NaN  \n",
       " 710                             NaN  )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_null_counts = data[['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']].notnull().sum()\n",
    "non_null_values = data[data['Unnamed: 2'].notnull() | data['Unnamed: 3'].notnull() | data['Unnamed: 4'].notnull()][['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']]\n",
    "non_null_counts, non_null_values.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VGXq5xBjpjfW",
    "outputId": "9aff7047-abdb-4398-876b-016593463619"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v2</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>{'Go': 0.05, 'until': 0.05, 'jurong': 0.05, 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>{'Ok': 0.16666666666666666, 'lar...': 0.166666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>{'Free': 0.03571428571428571, 'entry': 0.07142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>{'U': 0.18181818181818182, 'dun': 0.0909090909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>{'Nah': 0.07692307692307693, 'I': 0.0769230769...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  v2  \\\n",
       "0  Go until jurong point, crazy.. Available only ...   \n",
       "1                      Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3  U dun say so early hor... U c already then say...   \n",
       "4  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                                  tf  \n",
       "0  {'Go': 0.05, 'until': 0.05, 'jurong': 0.05, 'p...  \n",
       "1  {'Ok': 0.16666666666666666, 'lar...': 0.166666...  \n",
       "2  {'Free': 0.03571428571428571, 'entry': 0.07142...  \n",
       "3  {'U': 0.18181818181818182, 'dun': 0.0909090909...  \n",
       "4  {'Nah': 0.07692307692307693, 'I': 0.0769230769...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def compute_tf(text):\n",
    "    words = text.split()\n",
    "    total_words = len(words)\n",
    "    word_counts = Counter(words)\n",
    "    tf = {word: count / total_words for word, count in word_counts.items()}\n",
    "\n",
    "    return tf\n",
    "\n",
    "data['tf'] = data['v2'].apply(compute_tf)\n",
    "data[['v2', 'tf']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "ImubYnfqp63t",
    "outputId": "9f404c62-f435-48aa-91e8-414b74b242f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>07732584351</th>\n",
       "      <th>0800</th>\n",
       "      <th>08000930705</th>\n",
       "      <th>08002986030</th>\n",
       "      <th>08452810075over18</th>\n",
       "      <th>09061209465</th>\n",
       "      <th>09061701461</th>\n",
       "      <th>09066364589</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yours</th>\n",
       "      <th>yourself</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yup</th>\n",
       "      <th>ì_</th>\n",
       "      <th>ì¼1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  07732584351  0800  08000930705  08002986030  08452810075over18  \\\n",
       "0  0.0          0.0   0.0          0.0          0.0           0.000000   \n",
       "1  0.0          0.0   0.0          0.0          0.0           0.000000   \n",
       "2  0.0          0.0   0.0          0.0          0.0           0.037037   \n",
       "3  0.0          0.0   0.0          0.0          0.0           0.000000   \n",
       "4  0.0          0.0   0.0          0.0          0.0           0.000000   \n",
       "\n",
       "   09061209465  09061701461  09066364589   10  ...  yesterday   yo  you  your  \\\n",
       "0          0.0          0.0          0.0  0.0  ...        0.0  0.0  0.0   0.0   \n",
       "1          0.0          0.0          0.0  0.0  ...        0.0  0.0  0.0   0.0   \n",
       "2          0.0          0.0          0.0  0.0  ...        0.0  0.0  0.0   0.0   \n",
       "3          0.0          0.0          0.0  0.0  ...        0.0  0.0  0.0   0.0   \n",
       "4          0.0          0.0          0.0  0.0  ...        0.0  0.0  0.0   0.0   \n",
       "\n",
       "   yours  yourself  yummy  yup   ì_  ì¼1  \n",
       "0    0.0       0.0    0.0  0.0  0.0  0.0  \n",
       "1    0.0       0.0    0.0  0.0  0.0  0.0  \n",
       "2    0.0       0.0    0.0  0.0  0.0  0.0  \n",
       "3    0.0       0.0    0.0  0.0  0.0  0.0  \n",
       "4    0.0       0.0    0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 724 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "subset_data = data['v2'].head(100)\n",
    "vectorizer = CountVectorizer()\n",
    "word_counts = vectorizer.fit_transform(subset_data)\n",
    "tf_df = pd.DataFrame(word_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "tf_df = tf_df.divide(tf_df.sum(axis=1), axis=0)\n",
    "\n",
    "tf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emweK93dp-6E",
    "outputId": "734867c8-2cc2-462b-a99f-449d2d03b7fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 724)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "vDuiv7TsqVMV",
    "outputId": "5b7378ab-5b50-4834-ca0d-7eb625d4a49a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>ó_</th>\n",
       "      <th>û_</th>\n",
       "      <th>û_thanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8672 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "0  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "1  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "2  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "3  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "4  0.0  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "\n",
       "   0125698789   02  ...   ó_   û_  û_thanks  ûªm  ûªt  ûªve   ûï  ûïharry  \\\n",
       "0         0.0  0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0      0.0   \n",
       "1         0.0  0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0      0.0   \n",
       "2         0.0  0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0      0.0   \n",
       "3         0.0  0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0      0.0   \n",
       "4         0.0  0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0      0.0   \n",
       "\n",
       "    ûò  ûówell  \n",
       "0  0.0     0.0  \n",
       "1  0.0     0.0  \n",
       "2  0.0     0.0  \n",
       "3  0.0     0.0  \n",
       "4  0.0     0.0  \n",
       "\n",
       "[5 rows x 8672 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['v2'])\n",
    "tfidf_data = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "tfidf_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7TDV4b7oIgd",
    "outputId": "4fef51ef-00ca-4509-842c-487c0a1452ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9623318385650225,\n",
       " array([[965,   0],\n",
       "        [ 42, 108]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['v2'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data['v1'], test_size=0.2, random_state=42)\n",
    "\n",
    "lr_classifier = LogisticRegression(max_iter=1000)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy, conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1Tov7umGq4PT"
   },
   "outputs": [],
   "source": [
    "def extract_top_terms(message_index, tfidf_matrix, feature_names, N=5):\n",
    "    row_data = tfidf_matrix[message_index].toarray().flatten()\n",
    "\n",
    "    top_indices = row_data.argsort()[-N:][::-1]\n",
    "\n",
    "    top_terms = [(feature_names[i], row_data[i]) for i in top_indices]\n",
    "\n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKrvTuDtp4Dx",
    "outputId": "bf84cec8-a878-416d-a9fa-998ed37e9649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [('jurong', 0.3264252905795869),\n",
       "  ('amore', 0.3264252905795869),\n",
       "  ('buffet', 0.3116082237740733),\n",
       "  ('bugis', 0.2757654045621182),\n",
       "  ('cine', 0.2757654045621182)],\n",
       " 1: [('oni', 0.5465881710238072),\n",
       "  ('joking', 0.5236458071582338),\n",
       "  ('wif', 0.4316010362639011),\n",
       "  ('lar', 0.4082988561907181),\n",
       "  ('ok', 0.27211951321382544)],\n",
       " 2: [('fa', 0.46025256453051905),\n",
       "  ('entry', 0.3527103027641593),\n",
       "  ('08452810075over18', 0.23012628226525952),\n",
       "  ('21st', 0.2223624014303424),\n",
       "  ('2005', 0.2223624014303424)],\n",
       " 3: [('say', 0.588532244886041),\n",
       "  ('hor', 0.48845710205212745),\n",
       "  ('early', 0.3528609993425001),\n",
       "  ('dun', 0.3250496221664022),\n",
       "  ('already', 0.293626081506221)],\n",
       " 4: [('he', 0.4317278554771633),\n",
       "  ('lives', 0.38590759651744017),\n",
       "  ('nah', 0.34795073992273934),\n",
       "  ('usf', 0.3437619549300075),\n",
       "  ('goes', 0.3065400844986221)],\n",
       " 5: [('chgs', 0.3058662925725672),\n",
       "  ('rcv', 0.2919824379160986),\n",
       "  ('tb', 0.27449084967991694),\n",
       "  ('darling', 0.26824783161338317),\n",
       "  ('std', 0.24451322531066766)],\n",
       " 6: [('patent', 0.39931890051255087),\n",
       "  ('aids', 0.39931890051255087),\n",
       "  ('like', 0.3747940151467183),\n",
       "  ('treat', 0.3036497276132227),\n",
       "  ('brother', 0.29420339994257655)],\n",
       " 7: [('melle', 0.4455632669729008),\n",
       "  ('callertune', 0.42363685480452),\n",
       "  ('your', 0.26354207177659683),\n",
       "  ('as', 0.24744816150276217),\n",
       "  ('minnaminunginte', 0.2227816334864504)],\n",
       " 8: [('claim', 0.323288000837583),\n",
       "  ('09061701461', 0.27933837235844666),\n",
       "  ('kl341', 0.27933837235844666),\n",
       "  ('receivea', 0.27933837235844666),\n",
       "  ('reward', 0.2398974451464567)],\n",
       " 9: [('update', 0.4380576307052676),\n",
       "  ('mobile', 0.31247574578583537),\n",
       "  ('08002986030', 0.27953983424278844),\n",
       "  ('free', 0.2745615474858566),\n",
       "  ('entitled', 0.24352445463279676)]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['v2'])\n",
    "\n",
    "\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "top_terms_data = {i: extract_top_terms(i, tfidf_matrix, feature_names) for i in range(10)}\n",
    "\n",
    "top_terms_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIYdtlQFwQQp",
    "outputId": "d6ddde6a-327e-4e47-8f9e-12c47ddb21e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['ll',\n",
       "  'later',\n",
       "  'ok',\n",
       "  'got',\n",
       "  'sorry',\n",
       "  'know',\n",
       "  'home',\n",
       "  'ur',\n",
       "  'want',\n",
       "  'text'],\n",
       " 1: ['going',\n",
       "  'lor',\n",
       "  'come',\n",
       "  'today',\n",
       "  'claim',\n",
       "  'wat',\n",
       "  'good',\n",
       "  'prize',\n",
       "  'da',\n",
       "  'just'],\n",
       " 2: ['day',\n",
       "  'just',\n",
       "  'need',\n",
       "  'yes',\n",
       "  'love',\n",
       "  'stop',\n",
       "  'good',\n",
       "  'free',\n",
       "  'happy',\n",
       "  'babe'],\n",
       " 3: ['gt', 'lt', 'ur', 'ok', 'just', 'know', 'sent', 'good', 'send', 'text'],\n",
       " 4: ['free',\n",
       "  'pls',\n",
       "  'number',\n",
       "  'ur',\n",
       "  'nokia',\n",
       "  'new',\n",
       "  'time',\n",
       "  'just',\n",
       "  'tone',\n",
       "  'lol']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "n_topics = 5\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "doc_term_matrix = vectorizer.fit_transform(data['v2'])\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(doc_term_matrix)\n",
    "\n",
    "top_terms_per_topic = {}\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    top_features = topic.argsort()[-10:][::-1]\n",
    "    top_terms = [vectorizer.get_feature_names()[i] for i in top_features]\n",
    "    top_terms_per_topic[topic_idx] = top_terms\n",
    "\n",
    "top_terms_per_topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_C3XqKPiJvFJ",
    "outputId": "b4c24ed2-866f-4a8f-dcd9-95fa916ddac6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['v1', 'v2']]\n",
    "data.columns = ['label', 'message']\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBLevhlsJfIr",
    "outputId": "e1658fa3-5a02-44e6-febd-925edc530b69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 3956)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=5000)\n",
    "\n",
    "\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['message'])\n",
    "\n",
    "tfidf_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "NmdsszjQ93eK",
    "outputId": "c1678ec2-6a70-4fb2-b04e-2ee729660e90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.979372197309417,\n",
       "               precision    recall  f1-score      support\n",
       " ham            0.978659  0.997927  0.988199   965.000000\n",
       " spam           0.984733  0.860000  0.918149   150.000000\n",
       " accuracy       0.979372  0.979372  0.979372     0.979372\n",
       " macro avg      0.981696  0.928964  0.953174  1115.000000\n",
       " weighted avg   0.979476  0.979372  0.978775  1115.000000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'text' and 'label' are column names\n",
    "\n",
    "# Create a TfidfVectorizer instance\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Generate TF-IDF features\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM with a linear kernel\n",
    "svm_linear = SVC(kernel='linear', C=1)\n",
    "\n",
    "# Train the model\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_linear.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Convert classification report into DataFrame\n",
    "classification_report_df = pd.DataFrame(classification_rep).transpose()\n",
    "\n",
    "# Output accuracy and classification report DataFrame\n",
    "accuracy, classification_report_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "Ra50Zqgt8EQK",
    "outputId": "3f848009-a8c9-41d5-ab2e-0df8d34b4c30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.979372197309417,\n",
       "               precision    recall  f1-score      support\n",
       " ham            0.980612  0.995855  0.988175   965.000000\n",
       " spam           0.970370  0.873333  0.919298   150.000000\n",
       " accuracy       0.979372  0.979372  0.979372     0.979372\n",
       " macro avg      0.975491  0.934594  0.953737  1115.000000\n",
       " weighted avg   0.979234  0.979372  0.978909  1115.000000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Re-load the dataset since the previous environment was reset\n",
    "data_path = 'spam.csv'\n",
    "data = pd.read_csv(data_path, encoding='latin-1')\n",
    "data = data[['v1', 'v2']]  # We keep only the necessary columns\n",
    "data.columns = ['label', 'text']  # Rename the columns for convenience\n",
    "\n",
    "# Initialize a Bag of Words vectorizer\n",
    "bow_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=5000)\n",
    "\n",
    "# Fit and transform the data\n",
    "bow_features = bow_vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_features, data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM with a linear kernel\n",
    "svm_linear_bow = SVC(kernel='linear', C=1)\n",
    "\n",
    "# Train the model\n",
    "svm_linear_bow.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_bow = svm_linear_bow.predict(X_test_bow)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_bow = accuracy_score(y_test_bow, y_pred_bow)\n",
    "# Generate classification report\n",
    "classification_rep_bow = classification_report(y_test_bow, y_pred_bow, output_dict=True)\n",
    "\n",
    "# Convert classification report into DataFrame\n",
    "classification_report_bow_df = pd.DataFrame(classification_rep_bow).transpose()\n",
    "\n",
    "accuracy_bow, classification_report_bow_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "C1hnPzCHLxMy",
    "outputId": "4c69fb85-2d13-43ac-a1c5-c1f335ca11f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.968609865470852,\n",
       "               precision    recall  f1-score     support\n",
       " 0              0.979381  0.984456  0.981912   965.00000\n",
       " 1              0.896552  0.866667  0.881356   150.00000\n",
       " accuracy       0.968610  0.968610  0.968610     0.96861\n",
       " macro avg      0.937967  0.925561  0.931634  1115.00000\n",
       " weighted avg   0.968238  0.968610  0.968384  1115.00000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'text' and 'label' are column names\n",
    "\n",
    "# Load the dataset (if not already loaded)\n",
    "data_path = 'spam.csv'  # Update this path if necessary\n",
    "data = pd.read_csv(data_path, encoding='latin-1')\n",
    "data = data[['v1', 'v2']]  # Keep only the necessary columns\n",
    "data.columns = ['label', 'text']  # Rename the columns for convenience\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['label'])\n",
    "\n",
    "# Generate TF-IDF features (assuming this step is needed here)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['text'])\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler(with_mean=False)  # Set with_mean to False for sparse matrix compatibility\n",
    "\n",
    "# Create an instance of TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "\n",
    "# Apply SVD on the TF-IDF features\n",
    "svd_features = svd.fit_transform(tfidf_features)\n",
    "\n",
    "# Scale the data after applying SVD\n",
    "svd_features_scaled = scaler.fit_transform(svd_features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_svd, X_test_svd, y_train_svd, y_test_svd = train_test_split(svd_features_scaled, data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_linear_svd = SVC(kernel='linear', C=1)\n",
    "svm_linear_svd.fit(X_train_svd, y_train_svd)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_svd = svm_linear_svd.predict(X_test_svd)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy_svd = accuracy_score(y_test_svd, y_pred_svd)\n",
    "classification_rep_svd = classification_report(y_test_svd, y_pred_svd, output_dict=True)\n",
    "\n",
    "# Convert classification report into DataFrame\n",
    "classification_report_svd_df = pd.DataFrame(classification_rep_svd).transpose()\n",
    "\n",
    "# Output the accuracy and classification report DataFrame\n",
    "accuracy_svd, classification_report_svd_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "s4e7DEJ8MKXk",
    "outputId": "8a6a13e7-f17e-4022-bdd6-09816571770d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.979372197309417,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.98      1.00      0.99       965\\n           1       0.98      0.87      0.92       150\\n\\n    accuracy                           0.98      1115\\n   macro avg       0.98      0.93      0.95      1115\\nweighted avg       0.98      0.98      0.98      1115\\n')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Assuming 'data' is your DataFrame with 'text' and 'label' columns\n",
    "# and necessary preprocessing steps (like label encoding) have been done\n",
    "\n",
    "# Feature extraction for each model (TF-IDF, BoW, and SVD)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "bow_vectorizer = CountVectorizer()\n",
    "svd_transformer = TruncatedSVD(n_components=100)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(data['text'])\n",
    "bow_features = bow_vectorizer.fit_transform(data['text'])\n",
    "svd_features = scaler.fit_transform(svd_transformer.fit_transform(tfidf_features))\n",
    "\n",
    "# Split the data into training and testing sets for each feature set\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, data['label'], test_size=0.2, random_state=42)\n",
    "X_train_bow, X_test_bow, _ , _ = train_test_split(bow_features, data['label'], test_size=0.2, random_state=42)\n",
    "X_train_svd, X_test_svd, _ , _ = train_test_split(svd_features, data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train SVM models\n",
    "svm_linear = SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "svm_linear_bow = SVC(kernel='linear', C=1).fit(X_train_bow, y_train)\n",
    "svm_linear_svd = SVC(kernel='linear', C=1).fit(X_train_svd, y_train)\n",
    "\n",
    "# Make predictions using all three models\n",
    "y_pred_tfidf = svm_linear.predict(X_test)\n",
    "y_pred_bow = svm_linear_bow.predict(X_test_bow)\n",
    "y_pred_svd = svm_linear_svd.predict(X_test_svd)\n",
    "\n",
    "# Ensemble predictions using majority voting\n",
    "ensemble_predictions = []\n",
    "for tfidf, bow, svd in zip(y_pred_tfidf, y_pred_bow, y_pred_svd):\n",
    "    votes = [tfidf, bow, svd]\n",
    "    majority_vote = max(set(votes), key=votes.count)\n",
    "    ensemble_predictions.append(majority_vote)\n",
    "\n",
    "# Evaluate the ensemble model's performance\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "ensemble_classification_report = classification_report(y_test, ensemble_predictions)\n",
    "\n",
    "ensemble_accuracy, ensemble_classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "99tQK2Q4NpDz",
    "outputId": "742d71ce-1cbc-404b-9622-2714fdb1ea66"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute the decision function scores for each model\n",
    "score_tfidf = svm_linear.decision_function(X_test)\n",
    "score_bow = svm_linear_bow.decision_function(X_test_bow)\n",
    "score_svd = svm_linear_svd_array.decision_function(X_test_svd_array)\n",
    "\n",
    "# Compute FPR, TPR, and AUC for each model\n",
    "fpr_tfidf, tpr_tfidf, _ = roc_curve(y_test, score_tfidf, pos_label='spam')\n",
    "fpr_bow, tpr_bow, _ = roc_curve(y_test_bow, score_bow, pos_label='spam')\n",
    "fpr_svd, tpr_svd, _ = roc_curve(y_test_svd_array, score_svd, pos_label='spam')\n",
    "roc_auc_tfidf = auc(fpr_tfidf, tpr_tfidf)\n",
    "roc_auc_bow = auc(fpr_bow, tpr_bow)\n",
    "roc_auc_svd = auc(fpr_svd, tpr_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "KvSgufcPNjwk",
    "outputId": "e73755ca-f82b-49f4-a3fe-1d258b94ca6d"
   },
   "outputs": [],
   "source": [
    "# Function to plot ROC curve for a given model\n",
    "def plot_roc_curve(fpr, tpr, roc_auc, model_name):\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve - {model_name}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve for each model\n",
    "plot_roc_curve(fpr_tfidf, tpr_tfidf, roc_auc_tfidf, \"TF-IDF\")\n",
    "plot_roc_curve(fpr_bow, tpr_bow, roc_auc_bow, \"BoW\")\n",
    "plot_roc_curve(fpr_svd, tpr_svd, roc_auc_svd, \"SVD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "NwFzc5N4N-wa",
    "outputId": "a23a960b-0e57-4f2a-ef65-99c76ddef6c9"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'score_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-77db384612ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute ensemble scores based on the number of models predicting \"spam\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mensemble_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_svd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodel_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_score\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mensemble_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute ensemble scores based on the number of models predicting \"spam\"\n",
    "ensemble_scores = []\n",
    "for tfidf, bow, svd in zip(score_tfidf, score_bow, score_svd):\n",
    "    score = sum([1 if model_score > 0 else 0 for model_score in [tfidf, bow, svd]])\n",
    "    ensemble_scores.append(score)\n",
    "\n",
    "# Compute FPR, TPR, and AUC for the ensemble\n",
    "fpr_ensemble, tpr_ensemble, _ = roc_curve(y_test, ensemble_scores, pos_label='spam')\n",
    "roc_auc_ensemble = auc(fpr_ensemble, tpr_ensemble)\n",
    "\n",
    "# Plot the ROC curve for the ensemble\n",
    "plot_roc_curve(fpr_ensemble, tpr_ensemble, roc_auc_ensemble, \"Ensemble\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OcPLBm97QhP_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d1a42aaa053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Tokenize your text data using the existing tokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Find the number of unique words (vocabulary size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Tokenize your text data using the existing tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['message'])\n",
    "\n",
    "# Find the number of unique words (vocabulary size)\n",
    "num_words = len(tokenizer.word_index) + 1  # +1 accounts for the special padding or out-of-vocabulary token\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalAveragePooling1D, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "bow_vectorizer = CountVectorizer(stop_words='english', max_df=0.95, min_df=2, max_features=5000)\n",
    "\n",
    "# Fit and transform the data\n",
    "bow_features = bow_vectorizer.fit_transform(data['message'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_features.toarray(), data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Encoding the labels ('ham' and 'spam') into numerical format (0 and 1)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels for both training and test data\n",
    "y_train_bow = label_encoder.fit_transform(y_train_bow)\n",
    "y_test_bow = label_encoder.transform(y_test_bow)\n",
    "\n",
    "# Convert the encoded labels into float type for compatibility with TensorFlow/Keras\n",
    "y_train_bow = y_train_bow.astype(float)\n",
    "y_test_bow = y_test_bow.astype(float)\n",
    "num_words = 5000  # Example value, adjust based on your data\n",
    "sequence_length = 3956\n",
    "# Define the neural network model with attention\n",
    "input_text = Input(shape=(sequence_length,))  # Adjust sequence_length based on your data\n",
    "embedding_layer = Embedding(input_dim=num_words, output_dim=100)(input_text)  # Adjust embedding_dim\n",
    "attention_layer = Attention()([embedding_layer, embedding_layer])  # Apply self-attention\n",
    "pooled_attention = GlobalAveragePooling1D()(attention_layer)  # Pooling layer to summarize the attention weights\n",
    "\n",
    "# Further processing with dense layers\n",
    "dense1 = Dense(128, activation='relu')(pooled_attention)\n",
    "dense2 = Dense(64, activation='relu')(dense1)\n",
    "\n",
    "# Output layer with sigmoid activation function for binary classification\n",
    "output = Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_bow), y=y_train_bow)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = model.fit(\n",
    "    X_train_bow, y_train_bow, \n",
    "    epochs=50,  # Increased the number of epochs\n",
    "    batch_size=32, \n",
    "    class_weight=class_weight_dict, \n",
    "    validation_split=0.1, \n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_bow).ravel()\n",
    "\n",
    "# Compute ROC curve and AUC\n",
    "fpr, tpr, thresholds = roc_curve(y_test_bow, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate the confusion matrix to check false negatives and false positives\n",
    "conf_matrix = confusion_matrix(y_test_bow, (predictions > 0.5).astype(int))\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set the GPU you want to use (e.g., \"0\" or \"1\" or \"0,1\" for multiple GPUs)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
